{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "\n",
    "# Get environment variables if not set\n",
    "def _set_env(var: str):\n",
    "        if not os.environ.get(var):\n",
    "            os.environ[var] = getpass.getpass(f'Enter your {var} API key: ')\n",
    "\n",
    "# Check necessary environment variables\n",
    "_set_env('TAVILY_API_KEY')\n",
    "_set_env('LANGCHAIN_API_KEY')\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_PROJECT'] = 'langchain-rag-ollama'\n",
    "\n",
    "### Search\n",
    "\n",
    "# from langchain_community.tools.tavily_search import TavilySearchRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the model\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "local_llm = 'llama3.2'\n",
    "llm = ChatOllama(model=local_llm, temperature=0.0)\n",
    "llm_json_mode = ChatOllama(model=local_llm, temperature=0.0, format='json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector store and embedding model\n",
    "*Using basic query to test the vectorstore and embedding model.*\n",
    "\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 @ 01:33:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36membedding.embedding_models\u001b[0m:\u001b[36mget_bge_embedding\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mUsing device: mps\u001b[0m\n",
      "\u001b[32m2025-01-13 @ 01:33:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36membedding.embedding_models\u001b[0m:\u001b[36mget_bge_embedding\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLoading BGE embedding model: BAAI/bge-m3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 @ 01:34:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36membedding.embedding_models\u001b[0m:\u001b[36mget_bge_embedding\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mSuccessfully loaded BGE embedding model\u001b[0m\n",
      "\u001b[32m2025-01-13 @ 01:34:01\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36membedding.vector_store\u001b[0m:\u001b[36mretrieve_docs\u001b[0m:\u001b[36m91\u001b[0m - \u001b[33m\u001b[1mRetrieved 5 documents\u001b[0m\n",
      "language too, I think. When he first moved here, I put signs in large letters on his drawers and doors to help him find things, but it seems now it is more of a matter of not being able to process the written language itself. He can sound out the word, but takes him a while for it to register what the word means.  We have a lighted magnifying glass for him to look at picture books, but managing the magnifying glass has become too hard for him. His glasses are bifocals and self tinting but even that has been confusing for him so we ordered some plain glasses hoping that will help.\n",
      "{'author': 'Unknown', 'source': 'https://alzconnected.org/discussion/56340/it-s-time', 'source-tag': 'alzconnect', 'tag': 'Unknown', 'title': 'It’s time'}\n",
      "Are language and translation services available? You and your friend or family member have the right to have an interpreter present – it’s important that language not be a barrier to clear communication.\n",
      "If you or the person you care for prefer speaking in a language other than English, be sure to request a professional interpreter. Hospitals and clinicians are legally required to provide that service to you, so if a professional interpreter is unavailable, the health care organization should make arrangements for translation services via video or telephone.\n",
      "Written materials must be provided in your preferred language as well.\n",
      "Studies have shown that numerous, often dangerous errors can be made in home care when language is not taken into account at discharge. More than 200 different languages are spoken in the US, with approximately 25 million people speaking English at a level below “very well.” This is further complicated when the discussion includes complex medical information.\n",
      "{'author': 'Unknown', 'source': 'https://www.caregiver.org/resource/hospital-discharge-planning-guide-families-and-caregivers/', 'source-tag': 'agingcare', 'tag': '', 'title': 'Hospital Discharge Planning: A Guide for Families and Caregivers'}\n",
      "Do I have the right to an interpreter? More than 200 different languages are spoken in the US, with approximately 25 million people speaking English at a level below “very well.” And even if your first language is English, it can be difficult to understand complex medical information.\n",
      "For those who primarily speak a different language, and your doctor does not speak your language, comprehension is difficult if not impossible – and resulting misinformation can be life-threatening.\n",
      "Fortunately, based on the Civil Rights Act of 1964, patients have the right to the services of an interpreter—including sign language interpreters—in health care settings.\n",
      "Although there are now national certification programs to ensure that interpreters are competent to translate medical/health care language, there is still wide variation from state to state in the availability of such interpreters.\n",
      "{'author': 'Unknown', 'source': 'https://www.caregiver.org/resource/pathways-effective-communication-healthcare-providers-and-caregivers/', 'source-tag': 'agingcare', 'tag': '', 'title': 'Pathways to Effective Communication for Health Care Providers and Caregivers'}\n",
      "Bonjour main dans la main, Je suis française et très souvent sur ce forum où j’ai trouvé beaucoup de soutien et de réponses à mes questions. Effectivement, cela nécessite de parler anglais, ou d’utiliser deepl.com pour la traduction. Je me débrouille bien en anglais mais utilise régulièrement ce site de traduction pour aller plus vite. Je peux aider, mais la communauté ici est beaucoup plus riche que ce que je pourrais apporter seule. Ce serait dommage de n’échanger qu’en français. Donc si besoin, je peux aider à traduire. Et de toute manière comptez sur l’indulgente de nos amis ici si votre anglais est approximatif. In English for the others I am French and very often on this forum where I found a lot of support and answers to my questions. Indeed, it requires to speak English, or to use deepl.com for the translation. I can speak (or write) well in English but regularly use this translation site to go faster. I can help, but the community here is much richer than what I could bring\n",
      "{'author': 'Unknown', 'source': 'https://alzconnected.org/discussion/58642/besoin-de-reponses', 'source-tag': 'alzconnect', 'tag': 'Unknown', 'title': 'Besoin de réponses'}\n",
      "=======\n",
      "\n",
      "That is quite the salad! Do you nod and say \"yup, I understand\"? I myself have been practicing listening to mom and learning how to respond when I don't understand her. Acting surprised or concerned at the right times, things like that. She hasn't gotten to the word salad part yet, but I'm on the watch for it\n",
      "\n",
      "=======\n",
      "\n",
      "Yes, absolutely.  Been dealing with this for quite awhile.  And opposite world.  Cat/dog, girl/boy… it goes on and on.  Now I’d say cat and dog words are gone and some new made up jumble for those.  The communication aspect of this gross disease is one of the hardest. \n",
      "\n",
      "=======\n",
      "{'author': 'Unknown', 'source': 'https://alzconnected.org/discussion/61901/speech-question', 'source-tag': 'alzconnect', 'tag': 'Unknown', 'title': 'Speech question'}\n"
     ]
    }
   ],
   "source": [
    "from embedding.vector_store import VectorStore\n",
    "from embedding.embedding_models import EmbeddingModels\n",
    "\n",
    "embedding_model = EmbeddingModels().get_bge_embedding(model_name=\"BAAI/bge-m3\") # use default model\n",
    "chroma_kb = VectorStore.get_chroma_vectorstore(\n",
    "    vectorstore_path='./data/vector_database/peer_kb', \n",
    "    embedding=embedding_model\n",
    ")\n",
    "\n",
    "# query_text = 'what is ADRD' # failed, no results\n",
    "query_text = 'what is the specialty for Chinese language. ' \n",
    "similarity_search_res = VectorStore.retrieve_docs(query=query_text, vectorstore=chroma_kb, k=5)\n",
    "\n",
    "for doc in similarity_search_res:\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve grading \n",
    "*Preventing hallucination and erroneous retrieval that is not relevant to the question but based on the idiosyncrasies of the embedding model or chunking.*\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 @ 01:34:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcheckpoints.retrieval_grading\u001b[0m:\u001b[36mgrade_retrieval\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1mGrading relevance for question: what is the specialty for Chinese language. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from checkpoints.retrieval_grading import grade_retrieval\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Grade the retrieval results\n",
    "graded_docs = grade_retrieval(query_text, similarity_search_res)\n",
    "\n",
    "# Print graded results\n",
    "# for doc in graded_docs:\n",
    "#     print(f\"Document content: {doc}\")\n",
    "    \n",
    "# Filter out documents with relevance_score lower than 0.5\n",
    "class ReasonedDocument:\n",
    "    \"\"\"\n",
    "    A class to store the document, relevance score, and reasoning.\n",
    "    \"\"\"\n",
    "    \n",
    "    document: Document # Retrieved document from vector store in Document type\n",
    "    relevance_score: float # Relevance score by reasoning model\n",
    "    reasoning: str # Reasons for the relevance score\n",
    "    \n",
    "    def __init__(self, document, relevance_score, reasoning):\n",
    "        self.document = document\n",
    "        self.relevance_score = relevance_score\n",
    "        self.reasoning = reasoning\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"Document: {self.document}\\nRelevance Score: {self.relevance_score}\\nReasoning: {self.reasoning}\\n\"\n",
    "\n",
    "# filtered_docs = [doc for doc, grade in zip(similarity_search_res, graded_docs) if grade[\"relevance_score\"] >= 0.5]\n",
    "\n",
    "filtered_docs = []\n",
    "\n",
    "for doc, grade in zip(similarity_search_res, graded_docs):\n",
    "    if grade[\"relevance_score\"] >= 0.5:\n",
    "        reasoned_doc = ReasonedDocument(\n",
    "            document=doc,\n",
    "            relevance_score=grade[\"relevance_score\"],\n",
    "            reasoning=grade[\"reasoning\"]\n",
    "        )\n",
    "        filtered_docs.append(reasoned_doc)\n",
    "\n",
    "\n",
    "# Print filtered results\n",
    "for doc in filtered_docs:\n",
    "    print(doc)\n",
    "    # print(doc.metadata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate answer\n",
    "*Using the graded documents to generate an answer.*\n",
    "\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-13 @ 01:37:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.logger\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mLogger initialized successfully\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'filtered_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01manswer_generation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_answer\n\u001b[0;32m----> 3\u001b[0m context_chunks \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mdocument \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfiltered_docs\u001b[49m]\n\u001b[1;32m      5\u001b[0m answer \u001b[38;5;241m=\u001b[39m generate_answer(query_text, context_chunks)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filtered_docs' is not defined"
     ]
    }
   ],
   "source": [
    "from answer_generation import generate_answer\n",
    "\n",
    "context_chunks = [doc.document for doc in filtered_docs]\n",
    "\n",
    "# TODO: handle the case where context_chunks is empty, answer should specify that we don't have relevant information.\n",
    "\n",
    "answer = generate_answer(query_text, context_chunks)\n",
    "\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
